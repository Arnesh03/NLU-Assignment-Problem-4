\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage[most]{tcolorbox}
\usepackage{enumitem}
\usepackage{colortbl}

% Define Custom Colors
\definecolor{DeepBlue}{HTML}{1A365D}
\definecolor{SkyBlue}{HTML}{3182CE}
\definecolor{AccentOrange}{HTML}{DD6B20}
\definecolor{LightGray}{HTML}{F7FAFC}
\definecolor{DarkSlate}{HTML}{2D3748}

\geometry{margin=1in}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=SkyBlue,
    filecolor=AccentOrange,      
    urlcolor=SkyBlue,
    citecolor=DeepBlue,
}

% Section styling
\titleformat{\section}
  {\color{DeepBlue}\normalfont\Large\bfseries}
  {\color{DeepBlue}\thesection}{1em}{}
\titleformat{\subsection}
  {\color{SkyBlue}\normalfont\large\bfseries}
  {\color{SkyBlue}\thesubsection}{1em}{}

% Header and Footer
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancyhead[L]{\color{DarkSlate}\textit{NLU Assignment 1 -- Problem 4}}
\fancyhead[R]{\color{DarkSlate}Arnesh Sanjeev Singh}
\fancyfoot[C]{\color{DarkSlate}\thepage}

% Custom Abstract Box
\newtcolorbox{myabstract}{
  colback=LightGray,
  colframe=DeepBlue,
  fonttitle=\bfseries,
  title=Abstract,
  arc=4pt,
  boxrule=1pt,
  left=10pt,
  right=10pt,
  top=10pt,
  bottom=10pt,
}

% List styling
\setlist[itemize]{label=\color{AccentOrange}\textbullet, nosep}
\setlist[enumerate]{label=\color{DeepBlue}\arabic*., nosep}

\title{
    \vspace{-1.5cm}
    \begin{tcolorbox}[colback=DeepBlue, colframe=DeepBlue, arc=0pt, boxrule=0pt, left=10pt, right=10pt, top=20pt, bottom=20pt]
        \centering
        \color{white}
        \Huge \textbf{Distinguishing Sports and Politics}\\
        \vspace{0.5cm}
        \Large NLU Assignment 1 -- Problem 4
    \end{tcolorbox}
}
\author{
    \large \textbf{Arnesh Sanjeev Singh} \\
    \textit{Roll Number: M25CSE008}
}
\date{\today}

\begin{document}

\maketitle

\begin{myabstract}
This report details the development and evaluation of a text classification system designed to distinguish between documents from the \textbf{Sports} and \textbf{Politics} domains. Using the 20 Newsgroups dataset, we implemented and compared three machine learning models: Multinomial Naive Bayes, Logistic Regression, and Linear Support Vector Machine. Features were represented using TF-IDF vectorization with unigrams and bigrams. Our results show that even simple linear models achieve high accuracy (above 94\%), with Naive Bayes performing the best in various trials.
\end{myabstract}

\section{Introduction}
The task of classifying text into predefined categories is a fundamental problem in Natural Language Understanding (NLU). This assignment focuses on a binary classification problem: identifying whether a given newsgroup post belongs to the Sports domain or the Politics domain. 

The primary objectives of this study were:
\begin{itemize}
    \item To collect and preprocess a relevant subset of the 20 Newsgroups dataset.
    \item To explore different feature representation techniques, specifically TF-IDF and Bag-of-Words.
    \item To compare the performance of three classic machine learning algorithm.
    \item To analyze the limitations and failure cases of the implemented system.
\end{itemize}

\section{Data Collection}
For this task, I used the **20 Newsgroups dataset**, which is a widely used benchmark for text classification tasks. The dataset was accessed via the `scikit-learn` library.

\subsection{Category Selection}
Since the goal was to differentiate between Sports and Politics, I filtered the 20 topic categories to include only the most relevant ones:
\begin{itemize}
    \item \textbf{Sports}: \texttt{rec.sport.baseball}, \texttt{rec.sport.hockey}
    \item \textbf{Politics}: \texttt{talk.politics.guns}, \texttt{talk.politics.mideast}, \texttt{talk.politics.misc}
\end{itemize}

By including multiple sub-categories for both classes, the dataset provides a more robust representation of the domains. For example, "Politics" includes diverse topics like firearm legislation and middle-east conflicts, which helps the model learn a more general definition of the category.

\subsection{Preprocessing}
To ensure the model learns from the actual content rather than metadata artifacts, the following headers, footers, and quotes were removed from the documents using the \texttt{remove} parameter in \texttt{fetch\_20newsgroups}. This makes the task more difficult because the classifier cannot rely on header tags like "Subject: baseball" or specific email addresses.

\section{Dataset Description and Analysis}
After filtering, the final dataset contained **4,618 documents**. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{dataset_distribution.png}
    \caption{Distribution of documents between Sports and Politics classes.}
\end{figure}

As shown in Figure 1, the dataset is somewhat balanced but contains slightly more politics-related posts (56.8\%) than sports-related ones (43.2\%). This is expected since we chose three politics sub-categories and only two sports sub-categories.

\subsection{Lexical Characteristics}
A brief analysis of the vocabularies revealed distinct keywords for each class:
\begin{itemize}
    \item \textbf{Sports}: game, players, season, team, league, win, series, baseball, fans.
    \item \textbf{Politics}: government, rights, law, state, policy, israel, congress, president.
\end{itemize}
The presence of bigrams like "home run" (Sports) vs "white house" (Politics) also provides significant discriminatory power.

\clearpage
\section{Methodology}
\subsection{Feature Representation}
I evaluated two main feature representation techniques:
\begin{enumerate}
    \item \textbf{Bag of Words (BoW)}: Counting the frequency of each word in the document.
    \item \textbf{TF-IDF Vectorization}: Scaling word counts by their "uniqueness" across the whole corpus.
\end{enumerate}

In my experiments, TF-IDF slightly outperformed BoW by penalizing very common words (stop words) and highlighting domain-specific terms. I also used a \texttt{max\_features} limit of 10,000 to keep the model efficient.

\subsection{Algorithms Compared}
I compared three different machine learning models to solve the classification task:

\begin{enumerate}
    \item \textbf{Multinomial Naive Bayes (MNB)}: A probabilistic classifier based on Bayes' theorem. It's often the first choice for text because it handles discrete counts well even though it assumes features are independent.
    \item \textbf{Logistic Regression (LR)}: A linear model that estimates the probability of a class using a logistic function. It's robust and often performs better than NB when the independence assumption is violated.
    \item \textbf{Linear SVM (SGDClassifier)}: A Support Vector Machine that tries to find the best boundary (hyperplane) between classes. It's very efficient for large-scale text data.
\end{enumerate}

\section{Quantitative Comparisons}
The models were evaluated using an 80/20 train-test split. The performance metrics used were Accuracy, Precision, Recall, and F1-Score.

\begin{table}[H]
    \centering
    \caption{Performance Comparison of the Three Models}
    \rowcolors{2}{LightGray}{white}
    \begin{tabular}{lcccc}
        \rowcolor{DeepBlue}
        \textbf{\color{white}Model} & \textbf{\color{white}Accuracy} & \textbf{\color{white}Precision} & \textbf{\color{white}Recall} & \textbf{\color{white}F1-Score} \\
        \midrule
        Naive Bayes & \textbf{96.1\%} & 0.94 & 0.99 & 0.97 \\
        Logistic Regression & 95.5\% & 0.94 & 0.99 & 0.96 \\
        Linear SVM & 94.8\% & 0.94 & 0.97 & 0.96 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{model_comparison.png}
    \caption{Visual Comparison of Model Accuracies.}
\end{figure}

\subsection{Analysis}
Naive Bayes actually achieved the best performance here. This suggests that the word choices in Sports and Politics are so distinct that the "naive" independence assumption doesn't really handicap the model. 

Looking at the confusion matrix (Figure 4), we can see where the errors happen. For Naive Bayes, there were very few false positives for Politics, but some Sports articles were misclassified.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{cm_nb.png}
        \caption{Naive Bayes}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{cm_lr.png}
        \caption{Logistic Regression}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{cm_svm.png}
        \caption{Linear SVM}
    \end{subfigure}
    \caption{Confusion Matrices for all three machine learning models.}
\end{figure}

\clearpage
\section{Limitations}
While the accuracy is high, the system has some limitations:
\begin{enumerate}
    \item \textbf{Ambiguity}: Some posts might discuss both topics (e.g., politics in sports stadiums). The bag-of-words approach might struggle with these edge cases.
    \item \textbf{Static Vocabulary}: The model cannot handle new words it hasn't seen during training (Out-of-Vocabulary words).
    \item \textbf{Context}: Because we used a bag-of-words/n-gram approach, the model doesn't understand the semantic meaning of sentences, only the patterns of words.
\end{enumerate}

\section{Conclusion}
The task of distinguishing between Sports and Politics newsgroup posts is effectively solved with simple machine learning models. Accuracy consistently stays above 94\% across different algorithms. For this specific binary task, complex deep learning models are probably not necessary, as the vocabulary difference between the two fields is very clear.

\vspace{0.5cm}
\begin{tcolorbox}[colback=LightGray, colframe=SkyBlue, arc=4pt, title=Source Code]
    The complete implementation and source code for this problem can be found at: 
    \href{https://github.com/Arnesh03/NLU-Assignment-Problem-4}{https://github.com/Arnesh03/NLU-Assignment-Problem-4}
\end{tcolorbox}

\end{document}
